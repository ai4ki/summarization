{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be03dbe7",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "\n",
    "*Updated: 02/18/2022*\n",
    "\n",
    "This notebook allows you to summarize texts by using two different approaches.\n",
    "\n",
    "The first approach is called 'Extractive Summarization' (ES). As its name suggests, ES employs algorithms, which try to identify and extract the most relevant sentences from a text. ES is a computationally  efficient and fast summarization approach. \n",
    "\n",
    "The second approach is called 'Abstractive Summarization' (AS). This approach is based on (large) language models (LLM) for which the so called transformer architecture has become the de-facto standard. Having 'seen' enough pairs of text and a summary during training and leveraging its general language capabilities, an LLM can generate a summary that can contain original sentences verbatim alongside paraphrased or newly generated text. In contrast to ES, AS is very compute expensive.      \n",
    "\n",
    "Scientific texts strongly differ from most other texts in structure, form, and style. As LLMs are usually trained on vast troves of diverese texts scraped off the internet, we can't expect them to deal particularly well with scientific literature (unless we fine-tune them for this task). \n",
    "\n",
    "It is, therefore, strongly recommended to first use ES algorithms as they return original sentences from the text. AS might, instead, be a good starting point in case you have to write a summary, say, for a project proposal.     \n",
    "\n",
    "## Working with Jupyter notebooks\n",
    "\n",
    "In case you are not familiar with Jupyter notebooks, this is how to go about it: In order to execute a piece of code, click inside a cell (the ones with `[]` to the left) and press Shift+Enter. Wait until the cell is done--that's when the `*` in `[]` turned into a number--and move on to the next cell.\n",
    "\n",
    "If you get inconceivable error messages or the notebook gets stuck, choose \"Restart & Clear Output\" in the \"Kernel\" dropdown-menu above and start afresh. \n",
    "\n",
    "___\n",
    "**Please help us to improve this tool by [emailing us](mailto:ai4ki.dev@gmail.com?subject=ai4ki-tools:%20Summarization) your update ideas or error reports.**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0998c2",
   "metadata": {},
   "source": [
    "## Preparation: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70223922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from summarization_utils import *\n",
    "from transformers import pipeline\n",
    "from transformers import GPT2Tokenizer\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9eddd0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cea0e3",
   "metadata": {},
   "source": [
    "### Step 1: Load your text\n",
    "You can provide your text in the `.pdf` or `.txt`-formats.\n",
    "\n",
    "Note that we use Adobe's Document Services API for extracting PDF content. This API is not a free service and thus requires credentials. You can regsiter for a free trial  [here](https://www.adobe.io/apis/documentcloud/dcsdk/). In case you need support with authentication of your credentials, [email us](mailto:ai4ki.dev@gmail.com?subject=Summarization:%20Authentication%20Issues). \n",
    "\n",
    "In future updates of this notebook, we will try to implement an open source alternative like [this one](https://github.com/allenai/s2orc-doc2json).\n",
    "\n",
    "*Run the following cell and enter the name of your file.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the name of your file\n",
    "infile = input('Enter filename: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920f055",
   "metadata": {},
   "source": [
    "#### Alternatively, fetch an article from the Web \n",
    "*Run the following cell, enter the full URL of the article you want to summarize, and **proceed directly to summarization**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = input('Enter full URL: ')\n",
    "text_to_summarize = [fetch_article(url).strip().replace('\\n',' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819527d",
   "metadata": {},
   "source": [
    "### Step 2: Convert your text into a machine readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "fulltext, _, _, headers = preprocess_data(infile, base_path='./')\n",
    "if headers:\n",
    "    print(f\"==> Found the following chapters in {infile}\")\n",
    "    for i, h in enumerate(headers):\n",
    "        print(f\"{i}: {h['header']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2229c5",
   "metadata": {},
   "source": [
    "### Step 3: Choose chapter(s) for summarization\n",
    "You can either summarize a single chapter or a selection of chapters. Use the chapter numbering from the previous step (the numbers before the first colon) and change the variable `selected_chapters` in the cell below according to your choices.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your chapter number(s) here: \n",
    "selected_chapters = [1,4]\n",
    "\n",
    "text_to_summarize = []\n",
    "for chap in selected_chapters:\n",
    "    chap_data = headers[chap]\n",
    "    text_chap = fulltext[chap_data['idx_start']:chap_data['idx_end']].strip()\n",
    "    text_to_summarize.append(text_chap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429be54d",
   "metadata": {},
   "source": [
    "## Approach I: Extractive Summarization\n",
    "\n",
    "In this approach you can choose between the following summarization algorithms:  [LRS](https://pypi.org/project/lexrank/), [LSA](https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python), [LUHN](https://pypi.org/project/sumy/), and [KLS](https://pypi.org/project/sumy/). Follow the links, if you want to learn more about how these algorithms work. We found the LSA algorithm to produce good results: It often extracts sentences, which capture core ideas of a text.  \n",
    "\n",
    "*Run the following cell and enter the desired length of your summary as well as the summarization algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8882ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose length of summary (i.e. number of sentences)\n",
    "len_sum = input('Number of sentences: ')\n",
    "\n",
    "# Chose extraction algorithm\n",
    "ext_alg = input('Extractive algorithm: ')\n",
    "\n",
    "# Create the summary\n",
    "ext_summary = ''\n",
    "for chap in text_to_summarize:\n",
    "    chap_summ = extractive_summarizers(chap, algorithm=ext_alg, max_len=int(len_sum), lang='english')\n",
    "    ext_summary += chap_summ + '\\n\\n'\n",
    "\n",
    "# Print the summary\n",
    "print(f\"==> {ext_alg} SUMMARY: {ext_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98daf802",
   "metadata": {},
   "source": [
    "## Approach II: Abstractive Summarization\n",
    "\n",
    "You have two options here: first, summarization with a pre-trained T5 transformer model; second, summarization with GPT-2. T5 creates summaries, which often contain originial or only slightly paraphrased sentences. GPT-2, in contrast, mostly generates new text and, therefore, is more of an abstractive summarizer. We use the [Huggingface transformer library](https://huggingface.co/docs/transformers/index) for both options. \n",
    "\n",
    "Large language models set a limit to the length their combined input and output can have. This length is measured in 'tokens'. A token does not always correspond to a word, but, as a rule of thumb, you can think of 100 tokens corresponding to 75 words. Typical limits are 512, 1024, or 2048 tokens (see [here](https://beta.openai.com/docs/introduction/key-concepts) for a short introduction into tokenization).\n",
    "\n",
    "In order to be able to summarize longer texts, we first split the input text into equal chunks of appropriate size; we then summarize the first chunk, add this summary to the second chunk, and repeat this procedure until the last chunk. We set the maximum chunk size to 400 tokens (~300 words). This ensures that we stay safely below the models' limits (512 tokens and 1024 tokens for T5 and GPT-2, respectively).\n",
    "\n",
    "*Run the following cell **once** at the beginning of a session to instatiate the models.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the HuggingFace summarization pipeline\n",
    "summarizer = pipeline('summarization', model='t5-base', tokenizer='t5-base', framework='tf')\n",
    "\n",
    "# Set the GPT-2 tokenizer and instantiate GPT-2 model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af71584",
   "metadata": {},
   "source": [
    "### Option 1: Summarization with T5\n",
    "\n",
    "*Run the following cell to get a T5 summary of your selected text. Be patient, as completion might take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_summary = ''\n",
    "for chap in text_to_summarize:\n",
    "    # Split text into chunks, which fit into the transformer context window\n",
    "    chunks = chunk_text(chap, max_tokens=400)\n",
    "\n",
    "    # Generate chapter summaries\n",
    "    chap_summ = ''\n",
    "    for chunk in chunks:\n",
    "        prompt = chap_summ + ' ' + chunk\n",
    "        sum_tmp = summarizer(prompt.strip().replace('\\n',' '), min_length=30, max_length=100, do_sample=False)\n",
    "        chap_summ = sum_tmp[0]['summary_text']\n",
    "\n",
    "    # Concatenate chapter summaries\n",
    "    t5_summary += chap_summ + '\\n\\n'\n",
    "\n",
    "t5_summary = t5_summary.replace(\" .\", \".\")\n",
    "print(f'==> T5 SUMMARY: {t5_summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f473ab",
   "metadata": {},
   "source": [
    "### Option 2: Summarization with GPT-2\n",
    "\n",
    "The output of GPT-2 can be tuned with different parameters, the most important of which is `temperature`. Roughly speaking, temperature controls the randomness of the output. In our case, values close to zero will more likely create extractive summaries, while larger values allow for more abstractive summaries. You can experiment with different values by changing the parameter in the cell below.\n",
    "\n",
    "Note that GPT-2 can generate text, which is essentially bunk (at least with respect to the summarization task at hand). Therefore, you might have to go through a couple of trials until you get something useful. In order to improve GPT-2's summarization performance, we would have to fine-tune the model with suitable data.\n",
    "\n",
    "Also note that you can try summarization with GPT-3 in this [notebook](https://github.com/ai4ki/transformer-playground.git).  \n",
    "\n",
    "*Run the following cell to have GPT-2 summarize your text. Be patient, as completion might take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14413edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_summary = ''\n",
    "for chap in text_to_summarize:\n",
    "    # Split text into chunks, which fit into the transformer context window\n",
    "    chunks = chunk_text(chap, max_tokens=400)\n",
    "\n",
    "    # Generate chapter summaries\n",
    "    chap_summ = ''\n",
    "    for chunk in chunks:\n",
    "        prompt = chap_summ + ' ' + chunk\n",
    "        chap_summ = gpt2_summarizer(tokenizer, generator, prompt.strip().replace('\\n',' '), max_sum_length=100, temperature=0.7)\n",
    "        \n",
    "    # Concatenate chapter summaries\n",
    "    gpt2_summary += chap_summ + '\\n\\n'\n",
    "        \n",
    "print(f'==> SUMMARY: {gpt2_summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689911eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai4ki]",
   "language": "python",
   "name": "conda-env-ai4ki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
